{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Newcomer Data Gathering\n",
    "\n",
    "Aaron has a labeled dataset of newcomers to English Wikipedia on datasets.wikimedia.org. These newcomers are labeled as good-faith or bad-faith based on Wikipedians' judgements of the newcomers' edits in their first edit session. We will get ORES damaging, goodfaith, and reverted scores for the first n=50 revisions made by each newcomer in the data set. We will use these labeled revisions to build a model for predicting if a newcomer is goodfaith in the \"Good Faith Newcomer Prediction\" notebook.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "% matplotlib inline\n",
    "import pandas as pd\n",
    "import urllib\n",
    "import requests\n",
    "import os\n",
    "import concurrent.futures\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download newcomer quality data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DATA_URL = \"https://datasets.wikimedia.org/public-datasets/enwiki/rise-and-decline/newbie_quality_sample.tsv\"\n",
    "_ = urllib.request.urlretrieve(DATA_URL, \"newbie_quality_sample.tsv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels_df = pd.read_csv(\"newbie_quality_sample.tsv\", sep = '\\t')\n",
    "labels_df.index = labels_df.user_id\n",
    "labels_df[\"goodfaith_label\"] = labels_df.category > 2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True     875\n",
       "False    188\n",
       "Name: goodfaith_label, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_df[\"goodfaith_label\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels_df = labels_df.sort_values(\"user_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "labels_df.to_csv(\"../data/newcomer_labels.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Score early newcomer contribution history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_user_name(userid):\n",
    "    \"\"\"\n",
    "    Query mw api for a username given userid.\n",
    "    We need this because the mw api takes the username\n",
    "    and Aaron's data only has the userid\n",
    "    \"\"\"\n",
    "    url = 'http://en.wikipedia.org/w/api.php?action=query&format=json&list=users&usprop=&ususerids=%d'\n",
    "    try:\n",
    "        r = requests.get( url % userid).json()\n",
    "        return r[\"query\"]['users'][0]['name']\n",
    "    except:\n",
    "        print(\"Error getting username: \", userid)\n",
    "        return None\n",
    "\n",
    "def get_user_contribs(username, uclimit = 50):\n",
    "    \"\"\"\n",
    "    Get meta data for the first uclimit revisions\n",
    "    from user username\n",
    "    \"\"\"\n",
    "    params = {'action': 'query',\n",
    "           'format': 'json',\n",
    "           'list' : 'usercontribs',\n",
    "           'uclimit': uclimit,\n",
    "           'ucdir': 'newer',\n",
    "           'ucprop': 'ids|timestamp|title',\n",
    "           'ucuser': username\n",
    "          }\n",
    "    try:\n",
    "        r = requests.get('http://en.wikipedia.org/w/api.php', params=params).json()\n",
    "        return r[\"query\"]['usercontribs']\n",
    "    except:\n",
    "        print(\"Error getting contribs: \", username)\n",
    "        return []\n",
    "    \n",
    "def get_ores_score(model, revid):\n",
    "    \"\"\"\n",
    "    Get the ORES edit quality score from\n",
    "    model for revid\n",
    "    \"\"\"\n",
    "    url = 'https://ores.wikimedia.org/v2/scores/enwiki/%s/%d'\n",
    "    try:\n",
    "        r = requests.get( url % (model, revid)).json()\n",
    "        return r[\"scores\"]['enwiki'][model]['scores'][str(revid)]['probability']['true']\n",
    "    except:\n",
    "        print(\"Error getting scores: \", revid)\n",
    "        return None\n",
    "    \n",
    "def get_ores_labeled_contribs(userid, uclimit = 50):\n",
    "    \"\"\"\n",
    "    Given userid, get ORES scores for all three\n",
    "    edit quality models for the firts uclimit edits made\n",
    "    by user with userid\n",
    "    \"\"\"\n",
    "        \n",
    "    start = time.time()\n",
    "    \n",
    "    # get user name for contribs API\n",
    "    uname = get_user_name(userid)\n",
    "    \n",
    "    # get contribs \n",
    "    contribs = None\n",
    "    if uname is not None:\n",
    "        contribs = get_user_contribs(uname, uclimit = uclimit)\n",
    "        \n",
    "    \n",
    "    # get ORES scores for each contrib\n",
    "    models = ['reverted', 'goodfaith', 'damaging']\n",
    "    if contribs is not None:\n",
    "        for model in models:\n",
    "            for d_rev in contribs:\n",
    "                d_rev[model] = get_ores_score(model, d_rev['revid'])\n",
    "                     \n",
    "    end = time.time()           \n",
    "    print(\"Finished User: \", userid, \" in \", int(end-start), \"seconds\")\n",
    "    \n",
    "    return contribs\n",
    "\n",
    "def save_ores_labeled_contribs(userid):\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    user_file = \"../data/%d.csv\" % userid\n",
    "    if not os.path.isfile(user_file):\n",
    "        contribs = get_ores_labeled_contribs(userid)\n",
    "        if contribs is not None:\n",
    "            pd.DataFrame(contribs).to_csv(user_file % userid, index = False)\n",
    "\n",
    "\n",
    "def thread_function(helper_func, args_list, n_threads = 10):\n",
    "    with concurrent.futures.ThreadPoolExecutor(n_threads) as executor:\n",
    "        return list(executor.map(helper_func, args_list))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "_ = thread_function(save_ores_labeled_contribs, list(labels_df.user_id), n_threads = 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error reading:  ../data/36282.csv\n",
      "Error reading:  ../data/54943.csv\n",
      "Error reading:  ../data/70358.csv\n",
      "Error reading:  ../data/141314.csv\n",
      "Error reading:  ../data/219629.csv\n",
      "Error reading:  ../data/285599.csv\n",
      "Error reading:  ../data/531275.csv\n",
      "Error reading:  ../data/559047.csv\n",
      "Error reading:  ../data/593695.csv\n",
      "Error reading:  ../data/667147.csv\n",
      "Error reading:  ../data/679526.csv\n",
      "Error reading:  ../data/684238.csv\n",
      "Error reading:  ../data/691240.csv\n",
      "Error reading:  ../data/717021.csv\n",
      "Error reading:  ../data/775985.csv\n",
      "Error reading:  ../data/881279.csv\n",
      "Error reading:  ../data/1005136.csv\n",
      "Error reading:  ../data/1153106.csv\n",
      "Error reading:  ../data/1201426.csv\n",
      "Error reading:  ../data/1218423.csv\n",
      "Error reading:  ../data/1223674.csv\n",
      "Error reading:  ../data/1261094.csv\n",
      "Error reading:  ../data/1389088.csv\n",
      "Error reading:  ../data/1591094.csv\n",
      "Error reading:  ../data/1679226.csv\n",
      "Error reading:  ../data/1768117.csv\n",
      "Error reading:  ../data/1956584.csv\n",
      "Error reading:  ../data/1996887.csv\n",
      "Error reading:  ../data/2051829.csv\n",
      "Error reading:  ../data/2104109.csv\n",
      "Error reading:  ../data/2577714.csv\n",
      "Error reading:  ../data/2670395.csv\n",
      "Error reading:  ../data/2863973.csv\n",
      "Error reading:  ../data/2926342.csv\n",
      "Error reading:  ../data/2975482.csv\n",
      "Error reading:  ../data/3021346.csv\n",
      "Error reading:  ../data/3147794.csv\n",
      "Error reading:  ../data/3215933.csv\n",
      "Error reading:  ../data/3316061.csv\n",
      "Error reading:  ../data/3335763.csv\n",
      "Error reading:  ../data/3378072.csv\n",
      "Error reading:  ../data/3407424.csv\n",
      "Error reading:  ../data/3422609.csv\n",
      "Error reading:  ../data/3570898.csv\n",
      "Error reading:  ../data/3987015.csv\n",
      "Error reading:  ../data/4373302.csv\n",
      "Error reading:  ../data/4451406.csv\n",
      "Error reading:  ../data/4652528.csv\n",
      "Error reading:  ../data/5060604.csv\n",
      "Error reading:  ../data/5415746.csv\n",
      "Error reading:  ../data/5654754.csv\n",
      "Error reading:  ../data/5769303.csv\n",
      "Error reading:  ../data/5849814.csv\n",
      "Error reading:  ../data/6010648.csv\n",
      "Error reading:  ../data/6051771.csv\n",
      "Error reading:  ../data/6276594.csv\n",
      "Error reading:  ../data/6563688.csv\n",
      "Error reading:  ../data/6828887.csv\n",
      "Error reading:  ../data/7170597.csv\n",
      "Error reading:  ../data/7328866.csv\n",
      "Error reading:  ../data/7380869.csv\n",
      "Error reading:  ../data/7653774.csv\n",
      "Error reading:  ../data/8091316.csv\n",
      "Error reading:  ../data/8192838.csv\n",
      "Error reading:  ../data/8203794.csv\n",
      "Error reading:  ../data/8225996.csv\n",
      "Error reading:  ../data/8308709.csv\n",
      "Error reading:  ../data/8321853.csv\n",
      "Error reading:  ../data/8355997.csv\n",
      "Error reading:  ../data/8413769.csv\n",
      "Error reading:  ../data/8826575.csv\n",
      "Error reading:  ../data/8855466.csv\n",
      "Error reading:  ../data/8934807.csv\n",
      "Error reading:  ../data/9014166.csv\n",
      "Error reading:  ../data/9051533.csv\n",
      "Error reading:  ../data/9134377.csv\n",
      "Error reading:  ../data/9228296.csv\n",
      "Error reading:  ../data/9405201.csv\n",
      "Error reading:  ../data/9637240.csv\n",
      "Error reading:  ../data/9817151.csv\n",
      "Error reading:  ../data/9879396.csv\n",
      "Error reading:  ../data/9888697.csv\n",
      "Error reading:  ../data/10131244.csv\n",
      "Error reading:  ../data/10315258.csv\n",
      "Error reading:  ../data/10482573.csv\n",
      "Error reading:  ../data/10705097.csv\n",
      "Error reading:  ../data/10863557.csv\n",
      "Error reading:  ../data/11068259.csv\n",
      "Error reading:  ../data/11139842.csv\n",
      "Error reading:  ../data/11264110.csv\n",
      "Error reading:  ../data/11332077.csv\n",
      "Error reading:  ../data/11935790.csv\n",
      "Error reading:  ../data/11983992.csv\n",
      "Error reading:  ../data/12141876.csv\n",
      "Error reading:  ../data/12334842.csv\n",
      "Error reading:  ../data/12780973.csv\n",
      "Error reading:  ../data/12884223.csv\n",
      "Error reading:  ../data/12908700.csv\n",
      "Error reading:  ../data/12945020.csv\n",
      "Error reading:  ../data/12950587.csv\n",
      "Error reading:  ../data/13590187.csv\n",
      "Error reading:  ../data/13706209.csv\n",
      "Error reading:  ../data/13922525.csv\n",
      "Error reading:  ../data/13962291.csv\n",
      "Error reading:  ../data/14051653.csv\n",
      "Error reading:  ../data/14415581.csv\n",
      "Error reading:  ../data/14636288.csv\n",
      "Error reading:  ../data/14725824.csv\n"
     ]
    }
   ],
   "source": [
    "dfs = []\n",
    "\n",
    "for uid in labels_df.user_id:\n",
    "    user_file = \"../data/%d.csv\" % uid\n",
    "    try:\n",
    "        df = pd.read_csv(user_file)\n",
    "        dfs.append(df)\n",
    "    except:\n",
    "        print(\"Error reading: \", user_file)\n",
    "\n",
    "revisions_df = pd.concat(dfs).dropna()\n",
    "revisions_df.to_csv(\"../data/newcomer_revisions.csv\", index = False)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
